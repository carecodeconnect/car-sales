{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Sales Project\n",
    "\n",
    "## Working \n",
    "\n",
    "I quickly reviewed the task, the time required for completion, and thought about the tools I would need to complete the task.\n",
    "\n",
    "I knew the job role required MySQL and Python, and after seeing the `CSV` files contained tabular data, and looking at the task questions, I decided to use these as my main tools.\n",
    "\n",
    "As the task needed to be done in 2 hours, I decided on the quickest workflow, using the following tools:\n",
    "\n",
    "- `Jupyter` notebooks to write documentation and do exploratory data analysis (EDA)\n",
    "- `pandas` for data importing and wrangling on the `CSV` files\n",
    "- `pandasql` to run SQL queries on the `pandas` DataFrame\n",
    "- `pygwalker` to create quick interactive data visualisations (EDA) for the stakeholders\n",
    "- `streamlit` to make the visualisations accessible for non-tehnical stakeholders\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Create project folder structure\n",
    "2. Initialise `git` repository\n",
    "3. Create `conda` environment with Python 3.10 and key packages\n",
    "4. Start inspecting data\n",
    "\n",
    "## Discoveries\n",
    "\n",
    "### Tables\n",
    "\n",
    "I know straight away that to answer the questions, I will need to do some SQL joins, because there is more than one table.\n",
    "\n",
    "There are two tables (DataFrames) of car sales data: `purchase_data` and `vehicle_data`\n",
    "\n",
    "`customer_id` is the primary key of the `purchase_data` table\n",
    "\n",
    "`vehicle_id` is the primary key of the `vehicle_data` table\n",
    "\n",
    "So, I will use `vehicle_id` as the key to join the tables on.\n",
    "\n",
    "### `purchase_data`\n",
    "\n",
    "This table contains:\n",
    "\n",
    "- Information about car purchases per customer\n",
    "- `9` columns\n",
    "- `2_000_000` purchases (rows)\n",
    "\n",
    "### `test_vehicle_data`\n",
    "\n",
    "- Information about vehicles\n",
    "- `19` columns\n",
    "- `978` vehicles (rows)\n",
    "\n",
    "### Questions\n",
    "\n",
    "Next, because there is a lot of data in the tables, I'll read the questions, to know which variables are needed to answer them.\n",
    "\n",
    "I listed the questions, highlighted the variables, and then clarified which columns refer to which variables in the tables.\n",
    "\n",
    "I need to do this to check if there are any issues with data quality, missing values, or outliers, only for the relevant variables. Otherwise, this will take too long, due to the number of columns.\n",
    "\n",
    "## TODO\n",
    "\n",
    "**DONE** - Tables are already indexed using the `customer_id` (`purchase_data`) and `vehicle_id` (`vehicle_data`) columns, so I need to import the `CSV` to specify the index.\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "Strengths:\n",
    "\n",
    "- Automated workflow\n",
    "- Free and Open Source tools\n",
    "- Version control\n",
    "\n",
    "Weaknesses:\n",
    "\n",
    "- Coding is slower than using GUI\n",
    "- Choosing between SQL and pandas for queries\n",
    "- Folium could not display map, so went with pygwalker and datashader/holoviews/bokeh\n",
    "\n",
    "Ideas for next time:\n",
    "\n",
    "- `Tableau` for quicker workflow\n",
    "- `pygwalker` for entire project as interactive visualisations\n",
    "- `duckdb` to speed up SQL queries\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
